{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QsMF30KjN3r",
        "outputId": "76dbe1e4-8118-498f-d4f1-71d7ecfb171e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, responses, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 pyarrow-hotfix-0.6 responses-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import sys, math, re, xml.sax.saxutils\n",
        "import numpy as np\n",
        "from nltk.translate import meteor_score\n",
        "from packaging import version\n",
        "\n",
        "import evaluate\n",
        "\n",
        "\n",
        "if evaluate.config.PY_VERSION < version.parse(\"3.8\"):\n",
        "    import importlib_metadata\n",
        "else:\n",
        "    import importlib.metadata as importlib_metadata\n",
        "\n",
        "\n",
        "NLTK_VERSION = version.parse(importlib_metadata.version(\"nltk\"))\n",
        "if NLTK_VERSION >= version.Version(\"3.6.4\"):\n",
        "    from nltk import word_tokenize\n",
        "\n",
        "import nltk\n",
        "from nltk.translate import meteor_score\n",
        "from nltk import word_tokenize\n",
        "import numpy as np\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1axeNDPW8fQf",
        "outputId": "ba2489ad-5d42-4041-f76e-10a13f50e3ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data setup"
      ],
      "metadata": {
        "id": "4NnLFVA2LZ2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_code_snippet(snippet):\n",
        "    formatted_snippet = ' '.join(snippet.split())\n",
        "    symbols = ['=', '+', '-', '*', '/', '(', ')', '[', ']', ',', ':', '@', '.']\n",
        "    for symbol in symbols:\n",
        "        formatted_snippet = formatted_snippet.replace(symbol, f' {symbol} ')\n",
        "    return formatted_snippet"
      ],
      "metadata": {
        "id": "cacT4kRyKQX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format_code_snippet('''n = pts_des.shape[1]\n",
        "J = np.empty((0, 6))\n",
        "for i in range(n):\n",
        "    tmp_J = ibvs_jacobian(K, pts_obs[:, i].reshape(-1, 1), zs[i])\n",
        "    J = np.vstack((J, tmp_J))''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qEdzF1_LKUJa",
        "outputId": "1d925bc4-d3e1-4824-878f-6c26242c135e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'n  =  pts_des . shape [ 1 ]  J  =  np . empty (  ( 0 ,  6 )  )  for i in range ( n )  :  tmp_J  =  ibvs_jacobian ( K ,  pts_obs [  :  ,  i ]  . reshape (  - 1 ,  1 )  ,  zs [ i ]  )  J  =  np . vstack (  ( J ,  tmp_J )  ) '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BLEU Score (Abandoned)"
      ],
      "metadata": {
        "id": "cTDboiHqLGeF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HdiEAPwak02",
        "outputId": "1d485136-7c10-4d86-e336-051c10690a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.5773502691896257\n"
          ]
        }
      ],
      "source": [
        "# Added to bypass NIST-style pre-processing of hyp and ref files -- wade\n",
        "nonorm = 0\n",
        "\n",
        "preserve_case = False\n",
        "eff_ref_len = \"shortest\"\n",
        "\n",
        "normalize1 = [\n",
        "    ('<skipped>', ''),         # strip \"skipped\" tags\n",
        "    (r'-\\n', ''),              # strip end-of-line hyphenation and join lines\n",
        "    (r'\\n', ' '),              # join lines\n",
        "]\n",
        "normalize1 = [(re.compile(pattern), replace) for (pattern, replace) in normalize1]\n",
        "\n",
        "normalize2 = [\n",
        "    (r'([\\{-\\~\\[-\\` -\\&\\(-\\+\\:-\\@\\/])',r' \\1 '), # tokenize punctuation. apostrophe is missing\n",
        "    (r'([^0-9])([\\.,])',r'\\1 \\2 '),              # tokenize period and comma unless preceded by a digit\n",
        "    (r'([\\.,])([^0-9])',r' \\1 \\2'),              # tokenize period and comma unless followed by a digit\n",
        "    (r'([0-9])(-)',r'\\1 \\2 ')                    # tokenize dash when preceded by a digit\n",
        "]\n",
        "normalize2 = [(re.compile(pattern), replace) for (pattern, replace) in normalize2]\n",
        "\n",
        "def normalize(s):\n",
        "    '''Normalize and tokenize text. This is lifted from NIST mteval-v11a.pl.'''\n",
        "    # Added to bypass NIST-style pre-processing of hyp and ref files -- wade\n",
        "    if (nonorm):\n",
        "        return s.split()\n",
        "    if type(s) is not str:\n",
        "        s = \" \".join(s)\n",
        "    # language-independent part:\n",
        "    for (pattern, replace) in normalize1:\n",
        "        s = re.sub(pattern, replace, s)\n",
        "    s = xml.sax.saxutils.unescape(s, {'&quot;':'\"'})\n",
        "    # language-dependent part (assuming Western languages):\n",
        "    s = \" %s \" % s\n",
        "    if not preserve_case:\n",
        "        s = s.lower()\n",
        "    for (pattern, replace) in normalize2:\n",
        "        s = re.sub(pattern, replace, s)\n",
        "    return s.split()\n",
        "\n",
        "def count_ngrams(words, n=4):\n",
        "    counts = {}\n",
        "    for k in range(1,n+1):\n",
        "        for i in range(len(words)-k+1):\n",
        "            ngram = tuple(words[i:i+k])\n",
        "            counts[ngram] = counts.get(ngram, 0)+1\n",
        "    return counts\n",
        "\n",
        "def cook_refs(refs, n=4):\n",
        "    '''Takes a list of reference sentences for a single segment\n",
        "    and returns an object that encapsulates everything that BLEU\n",
        "    needs to know about them.'''\n",
        "\n",
        "    refs = [normalize(ref) for ref in refs]\n",
        "    maxcounts = {}\n",
        "    for ref in refs:\n",
        "        counts = count_ngrams(ref, n)\n",
        "        for (ngram,count) in counts.items():\n",
        "            maxcounts[ngram] = max(maxcounts.get(ngram,0), count)\n",
        "    return ([len(ref) for ref in refs], maxcounts)\n",
        "\n",
        "def cook_test(test, item, n=4):\n",
        "    '''Takes a test sentence and returns an object that\n",
        "    encapsulates everything that BLEU needs to know about it.'''\n",
        "    (reflens, refmaxcounts)=item\n",
        "    test = normalize(test)\n",
        "    result = {}\n",
        "    result[\"testlen\"] = len(test)\n",
        "\n",
        "    # Calculate effective reference sentence length.\n",
        "\n",
        "    if eff_ref_len == \"shortest\":\n",
        "        result[\"reflen\"] = min(reflens)\n",
        "    elif eff_ref_len == \"average\":\n",
        "        result[\"reflen\"] = float(sum(reflens))/len(reflens)\n",
        "    elif eff_ref_len == \"closest\":\n",
        "        min_diff = None\n",
        "        for reflen in reflens:\n",
        "            if min_diff is None or abs(reflen-len(test)) < min_diff:\n",
        "                min_diff = abs(reflen-len(test))\n",
        "                result['reflen'] = reflen\n",
        "\n",
        "    result[\"guess\"] = [max(len(test)-k+1,0) for k in range(1,n+1)]\n",
        "\n",
        "    result['correct'] = [0]*n\n",
        "    counts = count_ngrams(test, n)\n",
        "    for (ngram, count) in counts.items():\n",
        "        result[\"correct\"][len(ngram)-1] += min(refmaxcounts.get(ngram,0), count)\n",
        "\n",
        "    return result\n",
        "\n",
        "def score_cooked(allcomps, n=4, ground=0, smooth=1):\n",
        "    totalcomps = {'testlen':0, 'reflen':0, 'guess':[0]*n, 'correct':[0]*n}\n",
        "    for comps in allcomps:\n",
        "        for key in ['testlen','reflen']:\n",
        "            totalcomps[key] += comps[key]\n",
        "        for key in ['guess','correct']:\n",
        "            for k in range(n):\n",
        "                totalcomps[key][k] += comps[key][k]\n",
        "    logbleu = 0.0\n",
        "    all_bleus = []\n",
        "    for k in range(n):\n",
        "      correct = totalcomps['correct'][k]\n",
        "      guess = totalcomps['guess'][k]\n",
        "      addsmooth = 0\n",
        "      if smooth == 1 and k > 0:\n",
        "        addsmooth = 1\n",
        "      logbleu += math.log(correct + addsmooth + sys.float_info.min)-math.log(guess + addsmooth+ sys.float_info.min)\n",
        "      if guess == 0:\n",
        "        all_bleus.append(-10000000)\n",
        "      else:\n",
        "        all_bleus.append(math.log(correct + sys.float_info.min)-math.log( guess ))\n",
        "\n",
        "    logbleu /= float(n)\n",
        "    all_bleus.insert(0, logbleu)\n",
        "\n",
        "    brevPenalty = min(0,1-float(totalcomps['reflen'] + 1)/(totalcomps['testlen'] + 1))\n",
        "    for i in range(len(all_bleus)):\n",
        "      if i ==0:\n",
        "        all_bleus[i] += brevPenalty\n",
        "      all_bleus[i] = math.exp(all_bleus[i])\n",
        "    return all_bleus\n",
        "\n",
        "def compute_bleu_for_pair(code_snippet, summary, n=4, smooth=1):\n",
        "    '''Computes BLEU score for a single pair of code snippet and its summary.'''\n",
        "    # Normalize and prepare the data\n",
        "    ref = [normalize(code_snippet)]\n",
        "    candidate = normalize(summary)\n",
        "\n",
        "    # Compute BLEU score\n",
        "    refs = cook_refs(ref, n)\n",
        "    test = cook_test(candidate, refs, n)\n",
        "    score = score_cooked([test], n=n, smooth=smooth)  # Removed 'ground' parameter\n",
        "\n",
        "    # Return the BLEU score\n",
        "    return score[0]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    code_snippet = '''I love you'''\n",
        "    summary = '''I hate you'''\n",
        "    bleu_score = compute_bleu_for_pair(code_snippet, summary)\n",
        "    print(\"BLEU Score:\", bleu_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METEOR Score"
      ],
      "metadata": {
        "id": "XlaV7g4QLJ_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Meteor:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def compute_score(self, prediction, reference, alpha=0.9, beta=3, gamma=0.5):\n",
        "        if version.Version(nltk.__version__) >= version.Version(\"3.6.5\"):\n",
        "            prediction_tokens = word_tokenize(prediction)\n",
        "            reference_tokens = word_tokenize(reference)\n",
        "        else:\n",
        "            prediction_tokens = prediction.split()\n",
        "            reference_tokens = reference.split()\n",
        "\n",
        "        score = meteor_score.single_meteor_score(reference_tokens, prediction_tokens, alpha=alpha, beta=beta, gamma=gamma)\n",
        "        return score"
      ],
      "metadata": {
        "id": "yEByWkrt4lFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero shot results"
      ],
      "metadata": {
        "id": "PPvlEyO6LRbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meteor = Meteor()\n",
        "score1 = meteor.compute_score(\"Reverses a list and finds the index of a value in it, considering the reversed order\", \"return the last index of the value in the list\")\n",
        "score2 = meteor.compute_score(\"Retrieves a value from a map using a string key; if not found, returns a default value\", \"returns the object associated with the specified name of the child 's node\")\n",
        "score3 = meteor.compute_score(\"Populates a NumPy matrix with ratings based on user and item IDs from a dataset\", \"create a user-item matrix from the dataset\")\n",
        "score4 = meteor.compute_score(\"Returns the value of a variable called frame rate\", \"returns the frame rate value for the encoding process\")\n",
        "score5 = meteor.compute_score(\"Adds a key-value pair to a parameter dictionary\", \"sets the value of a parameter\")\n",
        "score6 = meteor.compute_score(\"Returns the name of the parent directory of a file path\", \"get the topic name from the file path\")\n",
        "score7 = meteor.compute_score(\"Performs a series of mathematical operations on a NumPy array\", \"project points into camera\")\n",
        "score8 = meteor.compute_score(\"Reads data from an input stream and handles exceptions\", \"tests if the content length set in the stream equals the bytes read from the stream, if any exception is thrown, then the test fails.\")\n",
        "score9 = meteor.compute_score(\"Computes a direction cosine matrix (DCM) from roll pitch yaw angles\", \"generate rotation matrix from roll, pitch, yaw Euler angles\")\n",
        "score10 = meteor.compute_score(\"Creates a server socket with an arbitrary port and starts a Python process\",\"starts the python script\")\n",
        "\n",
        "for i in range(1, 11):\n",
        "    score_var_name = f\"score{i}\"\n",
        "    print(f\"{score_var_name}: {globals()[score_var_name]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekpkwjKTLPyP",
        "outputId": "fba34447-08d6-45e5-c31f-e28f995d3167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score1: 0.5349990463475109\n",
            "score2: 0.07352941176470588\n",
            "score3: 0.25641025641025644\n",
            "score4: 0.41333333333333333\n",
            "score5: 0.30241935483870974\n",
            "score6: 0.4481927710843373\n",
            "score7: 0.0\n",
            "score8: 0.07662835249042145\n",
            "score9: 0.38070436507936506\n",
            "score10: 0.20408163265306123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few shot results"
      ],
      "metadata": {
        "id": "TbaqJQaQLTqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meteor = Meteor()\n",
        "score1 = meteor.compute_score(\"Defines a function rindex that returns the last index of a value in a list lst\", \"return the last index of the value in the list\")\n",
        "score2 = meteor.compute_score(\"Defines an object function that retrieves a value from a map if it exists, otherwise returns a default value\", \"returns the object associated with the specified name of the child 's node\")\n",
        "score3 = meteor.compute_score(\"Initializes a matrix with zeros and populates it with ratings from a dataset\", \"create a user-item matrix from the dataset\")\n",
        "score4 = meteor.compute_score(\"Defines an integer function that returns the value of frame rate\", \"returns the frame rate value for the encoding process\")\n",
        "score5 = meteor.compute_score(\"Defines a void function that puts key-value pairs into a parameter map\", \"sets the value of a parameter\")\n",
        "score6 = meteor.compute_score(\"Defines a function get_topic_name that extracts the name of the parent directory from a file path\", \"get the topic name from the file path\")\n",
        "score7 = meteor.compute_score(\"Performs a series of operations on arrays pts and pts_cam\", \"project points into camera\")\n",
        "score8 = meteor.compute_score(\"Reads data from an input stream, checks its length, and consumes the stream using utility methods\", \"tests if the content length set in the stream equals the bytes read from the stream, if any exception is thrown, then the test fails.\")\n",
        "score9 = meteor.compute_score(\"Defines a function dcm_from_rpy that computes a Direction Cosine Matrix from roll, pitch, and yaw angles\", \"generate rotation matrix from roll, pitch, yaw Euler angles\")\n",
        "score10 = meteor.compute_score(\"Creates a server socket on an available port and starts a Python server\",\"starts the python script\")\n",
        "\n",
        "for i in range(1, 11):\n",
        "    score_var_name = f\"score{i}\"\n",
        "    print(f\"{score_var_name}: {globals()[score_var_name]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRJs2PJv3Hlc",
        "outputId": "d2698d21-e1d4-4a94-95a7-64b904505f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score1: 0.6625884433962265\n",
            "score2: 0.072992700729927\n",
            "score3: 0.26315789473684215\n",
            "score4: 0.4043478260869566\n",
            "score5: 0.3872053872053872\n",
            "score6: 0.48453282828282834\n",
            "score7: 0.0\n",
            "score8: 0.14814814814814814\n",
            "score9: 0.6657318376068376\n",
            "score10: 0.20408163265306123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain of Thought results"
      ],
      "metadata": {
        "id": "lVRHgCJMLVVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meteor = Meteor()\n",
        "score1 = meteor.compute_score(\"The code's purpose is to return the last index of the given value in the list\", \"return the last index of the value in the list\")\n",
        "score2 = meteor.compute_score(\"The purpose of this code is to get a value from a map with a fallback value if the key is not present\", \"returns the object associated with the specified name of the child 's node\")\n",
        "score3 = meteor.compute_score(\"The purpose is to create a user-item rating matrix from a dataset\", \"create a user-item matrix from the dataset\")\n",
        "score4 = meteor.compute_score(\"The purpose is to retrieve and return the value of the frame rate\", \"returns the frame rate value for the encoding process\")\n",
        "score5 = meteor.compute_score(\"The purpose is to set key value pairs in parameters\", \"sets the value of a parameter\")\n",
        "score6 = meteor.compute_score(\"The purpose is to obtain the name of the parent directory from the file path\", \"get the topic name from the file path\")\n",
        "score7 = meteor.compute_score(\"The purpose seems to be some form of geometric or mathematical transformation on data represented by arrays\", \"project points into camera\")\n",
        "score8 = meteor.compute_score(\"The purpose appears to be related to managing input streams and handling exceptions\", \"tests if the content length set in the stream equals the bytes read from the stream, if any exception is thrown, then the test fails.\")\n",
        "score9 = meteor.compute_score(\"The purpose is to calculate a direction cosine matrix from roll pitch yaw angles\", \"generate rotation matrix from roll, pitch, yaw Euler angles\")\n",
        "score10 = meteor.compute_score(\"The purpose seems to be setting up a server socket and initializing a python interpreter\",\"starts the python script\")\n",
        "\n",
        "for i in range(1, 11):\n",
        "    score_var_name = f\"score{i}\"\n",
        "    print(f\"{score_var_name}: {globals()[score_var_name]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rBvlX1b4J6R",
        "outputId": "9bb1b92e-2cd4-4fbf-fbf0-24464fe239d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score1: 0.9308411214953272\n",
            "score2: 0.17857142857142858\n",
            "score3: 0.6394557823129252\n",
            "score4: 0.5437352245862884\n",
            "score5: 0.3125\n",
            "score6: 0.7295331925873797\n",
            "score7: 0.0\n",
            "score8: 0.07547169811320754\n",
            "score9: 0.45231071779744353\n",
            "score10: 0.19607843137254904\n"
          ]
        }
      ]
    }
  ]
}